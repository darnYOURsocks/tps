# TPS Reasoning Engine v6 - Docker Deployment Configuration
# Complete containerized deployment with all services

version: '3.8'

services:
  # Main TPS API Server
  tps-api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: tps-api
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://tps-redis:6379/0
      - DATABASE_URL=postgresql://tps_user:tps_password@tps-postgres:5432/tps_db
      - SECRET_KEY=${SECRET_KEY:-tps-secret-key-change-in-production}
      - DEBUG=false
      - WORKERS=4
    depends_on:
      - tps-redis
      - tps-postgres
    networks:
      - tps-network
    volumes:
      - ./logs:/app/logs
      - ./configurations:/app/configurations
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # TPS Web Interface
  tps-web:
    build:
      context: .
      dockerfile: docker/Dockerfile.web
    container_name: tps-web
    ports:
      - "3000:80"
    environment:
      - API_URL=http://tps-api:8000
      - NODE_ENV=production
    depends_on:
      - tps-api
    networks:
      - tps-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and sessions
  tps-redis:
    image: redis:7-alpine
    container_name: tps-redis
    ports:
      - "6379:6379"
    networks:
      - tps-network
    volumes:
      - tps-redis-data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # PostgreSQL database
  tps-postgres:
    image: postgres:15-alpine
    container_name: tps-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=tps_db
      - POSTGRES_USER=tps_user
      - POSTGRES_PASSWORD=tps_password
    networks:
      - tps-network
    volumes:
      - tps-postgres-data:/var/lib/postgresql/data
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tps_user -d tps_db"]
      interval: 10s
      timeout: 5s
      retries: 3

  # TPS Integration Services (Slack, Discord, etc.)
  tps-integrations:
    build:
      context: .
      dockerfile: docker/Dockerfile.integrations
    container_name: tps-integrations
    environment:
      - REDIS_URL=redis://tps-redis:6379/1
      - API_URL=http://tps-api:8000
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_SIGNING_SECRET=${SLACK_SIGNING_SECRET}
      - SLACK_APP_TOKEN=${SLACK_APP_TOKEN}
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - WHATSAPP_ACCESS_TOKEN=${WHATSAPP_ACCESS_TOKEN}
    depends_on:
      - tps-api
      - tps-redis
    networks:
      - tps-network
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

  # Monitoring with Prometheus
  tps-prometheus:
    image: prom/prometheus:latest
    container_name: tps-prometheus
    ports:
      - "9090:9090"
    networks:
      - tps-network
    volumes:
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
      - tps-prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  # Grafana for visualization
  tps-grafana:
    image: grafana/grafana:latest
    container_name: tps-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - tps-network
    volumes:
      - tps-grafana-data:/var/lib/grafana
      - ./docker/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./docker/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - tps-prometheus
    restart: unless-stopped

  # Nginx reverse proxy
  tps-nginx:
    image: nginx:alpine
    container_name: tps-nginx
    ports:
      - "80:80"
      - "443:443"
    networks:
      - tps-network
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./docker/nginx/conf.d:/etc/nginx/conf.d
      - ./docker/ssl:/etc/nginx/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - tps-api
      - tps-web
    restart: unless-stopped

  # Background task worker
  tps-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.worker
    container_name: tps-worker
    environment:
      - REDIS_URL=redis://tps-redis:6379/2
      - DATABASE_URL=postgresql://tps_user:tps_password@tps-postgres:5432/tps_db
      - WORKER_CONCURRENCY=4
    depends_on:
      - tps-redis
      - tps-postgres
    networks:
      - tps-network
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

  # TPS Analytics and Reporting
  tps-analytics:
    build:
      context: .
      dockerfile: docker/Dockerfile.analytics
    container_name: tps-analytics
    environment:
      - DATABASE_URL=postgresql://tps_user:tps_password@tps-postgres:5432/tps_db
      - REDIS_URL=redis://tps-redis:6379/3
      - REPORT_SCHEDULE=0 2 * * *  # Daily at 2 AM
    depends_on:
      - tps-postgres
      - tps-redis
    networks:
      - tps-network
    volumes:
      - ./reports:/app/reports
      - ./logs:/app/logs
    restart: unless-stopped

networks:
  tps-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  tps-redis-data:
    driver: local
  tps-postgres-data:
    driver: local
  tps-prometheus-data:
    driver: local
  tps-grafana-data:
    driver: local

---
# docker/Dockerfile.api
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash tps
RUN chown -R tps:tps /app
USER tps

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "4", "--worker-class", "uvicorn.workers.UvicornWorker", "tps_api_server:app"]

---
# docker/Dockerfile.web
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy source code and build
COPY . .
RUN npm run build

# Production stage
FROM nginx:alpine

# Copy built application
COPY --from=builder /app/dist /usr/share/nginx/html

# Copy nginx configuration
COPY docker/nginx/web.conf /etc/nginx/conf.d/default.conf

# Add health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD curl -f http://localhost/health || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]

---
# docker/Dockerfile.integrations
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements-integrations.txt .
RUN pip install --no-cache-dir -r requirements-integrations.txt

# Copy integration code
COPY tps_integration_connectors.py .
COPY tps_reasoning_wave_v6.py .

# Create non-root user
RUN useradd --create-home --shell /bin/bash tps
RUN chown -R tps:tps /app
USER tps

CMD ["python", "tps_integration_connectors.py"]

---
# docker/Dockerfile.worker
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy worker code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash tps
RUN chown -R tps:tps /app
USER tps

CMD ["celery", "worker", "-A", "tps_worker", "--loglevel=info", "--concurrency=4"]

---
# docker/Dockerfile.analytics
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    cron \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements-analytics.txt .
RUN pip install --no-cache-dir -r requirements-analytics.txt

# Copy analytics code
COPY tps_analytics.py .
COPY tps_reasoning_wave_v6.py .

# Setup cron for scheduled reports
COPY docker/crontab /etc/cron.d/tps-analytics
RUN chmod 0644 /etc/cron.d/tps-analytics
RUN crontab /etc/cron.d/tps-analytics

# Create non-root user
RUN useradd --create-home --shell /bin/bash tps
RUN chown -R tps:tps /app
USER tps

CMD ["cron", "-f"]

---
# docker/nginx/nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream tps_api {
        server tps-api:8000;
    }

    upstream tps_web {
        server tps-web:80;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=web:10m rate=50r/s;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";

    server {
        listen 80;
        server_name _;

        # API endpoints
        location /api/ {
            limit_req zone=api burst=5 nodelay;
            proxy_pass http://tps_api/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_timeout 30s;
        }

        # Health checks
        location /health {
            proxy_pass http://tps_api/health;
            access_log off;
        }

        # Web interface
        location / {
            limit_req zone=web burst=10 nodelay;
            proxy_pass http://tps_web/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Monitoring endpoints
        location /metrics {
            proxy_pass http://tps-prometheus:9090/;
            auth_basic "Monitoring";
            auth_basic_user_file /etc/nginx/.htpasswd;
        }

        location /grafana/ {
            proxy_pass http://tps-grafana:3000/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}

---
# docker/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'tps-api'
    static_configs:
      - targets: ['tps-api:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'tps-web'
    static_configs:
      - targets: ['tps-web:80']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['tps-redis:6379']

  - job_name: 'postgres'
    static_configs:
      - targets: ['tps-postgres:5432']

  - job_name: 'nginx'
    static_configs:
      - targets: ['tps-nginx:80']

---
# docker/init-db.sql
-- TPS Reasoning Engine Database Schema

-- Users table
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(255) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(50) DEFAULT 'user',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_active BOOLEAN DEFAULT true
);

-- Reasoning sessions table
CREATE TABLE IF NOT EXISTS reasoning_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id INTEGER REFERENCES users(id),
    input_text TEXT NOT NULL,
    tps_scores JSONB,
    wave_progression JSONB,
    insights JSONB,
    success_metrics JSONB,
    meta_observations JSONB,
    configuration_used VARCHAR(255),
    processing_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- System configurations table
CREATE TABLE IF NOT EXISTS system_configurations (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) UNIQUE NOT NULL,
    configuration JSONB NOT NULL,
    created_by INTEGER REFERENCES users(id),
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Integration platforms table
CREATE TABLE IF NOT EXISTS integration_platforms (
    id SERIAL PRIMARY KEY,
    platform_name VARCHAR(100) NOT NULL,
    configuration JSONB,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User sessions across platforms
CREATE TABLE IF NOT EXISTS user_platform_sessions (
    id SERIAL PRIMARY KEY,
    platform_user_id VARCHAR(255) NOT NULL,
    platform_name VARCHAR(100) NOT NULL,
    session_data JSONB,
    last_interaction TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(platform_user_id, platform_name)
);

-- Performance metrics
CREATE TABLE IF NOT EXISTS performance_metrics (
    id SERIAL PRIMARY KEY,
    metric_name VARCHAR(255) NOT NULL,
    metric_value DECIMAL,
    tags JSONB,
    recorded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- API usage tracking
CREATE TABLE IF NOT EXISTS api_usage (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    endpoint VARCHAR(255),
    method VARCHAR(10),
    status_code INTEGER,
    response_time_ms INTEGER,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for performance
CREATE INDEX IF NOT EXISTS idx_reasoning_sessions_user_id ON reasoning_sessions(user_id);
CREATE INDEX IF NOT EXISTS idx_reasoning_sessions_created_at ON reasoning_sessions(created_at);
CREATE INDEX IF NOT EXISTS idx_user_platform_sessions_platform ON user_platform_sessions(platform_name, platform_user_id);
CREATE INDEX IF NOT EXISTS idx_performance_metrics_name_time ON performance_metrics(metric_name, recorded_at);
CREATE INDEX IF NOT EXISTS idx_api_usage_user_time ON api_usage(user_id, timestamp);

-- Default admin user (password: admin123 - change in production!)
INSERT INTO users (username, email, password_hash, role) 
VALUES ('admin', 'admin@tps-system.local', '$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/LewdBPj/h1qZpRmjO', 'admin')
ON CONFLICT (username) DO NOTHING;

-- Default system configurations
INSERT INTO system_configurations (name, configuration, created_by)
VALUES 
    ('default', '{"template": "basic_advisor", "domain_weights": {"chemistry": 0.25, "biology": 0.25, "psychology": 0.25, "physics": 0.25}}', 1),
    ('therapeutic_support', '{"template": "therapeutic_support", "domain_weights": {"chemistry": 0.1, "biology": 0.3, "psychology": 0.5, "physics": 0.1}}', 1),
    ('decision_making', '{"template": "decision_making", "domain_weights": {"chemistry": 0.2, "biology": 0.2, "psychology": 0.3, "physics": 0.3}}', 1)
ON CONFLICT (name) DO NOTHING;

---
# docker/crontab
# TPS Analytics Cron Jobs
0 2 * * * /usr/local/bin/python /app/tps_analytics.py --daily-report
0 0 * * 0 /usr/local/bin/python /app/tps_analytics.py --weekly-report
0 0 1 * * /usr/local/bin/python /app/tps_analytics.py --monthly-report

---
# .env.example
# TPS Reasoning Engine v6 - Environment Configuration
# Copy this file to .env and update with your values

# API Configuration
SECRET_KEY=your-super-secret-key-here
DEBUG=false
API_HOST=0.0.0.0
API_PORT=8000
WORKERS=4

# Database Configuration
DATABASE_URL=postgresql://tps_user:tps_password@localhost:5432/tps_db
REDIS_URL=redis://localhost:6379/0

# Integration Platform Tokens
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token
SLACK_SIGNING_SECRET=your-slack-signing-secret
SLACK_APP_TOKEN=xapp-your-slack-app-token

DISCORD_BOT_TOKEN=your-discord-bot-token

TELEGRAM_BOT_TOKEN=your-telegram-bot-token

WHATSAPP_ACCESS_TOKEN=your-whatsapp-access-token
WHATSAPP_PHONE_NUMBER_ID=your-phone-number-id
WHATSAPP_VERIFY_TOKEN=your-verify-token

# Microsoft Teams
TEAMS_APP_ID=your-teams-app-id
TEAMS_APP_PASSWORD=your-teams-app-password

# Monitoring
GRAFANA_PASSWORD=your-grafana-admin-password

# SSL Configuration (for production)
SSL_CERT_PATH=/etc/ssl/certs/tps.crt
SSL_KEY_PATH=/etc/ssl/private/tps.key

# External Services
OPENAI_API_KEY=your-openai-api-key-if-needed
ANTHROPIC_API_KEY=your-anthropic-api-key-if-needed

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/tps.log

# Performance
MAX_REQUESTS_PER_MINUTE=60
CACHE_TTL=3600
SESSION_TIMEOUT=86400

---
# requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
gunicorn==21.2.0
redis==5.0.1
psycopg2-binary==2.9.9
sqlalchemy==2.0.23
alembic==1.12.1
pydantic==2.5.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6
aiofiles==23.2.1
celery==5.3.4
prometheus-client==0.19.0
structlog==23.2.0
click==8.1.7
rich==13.7.0
pyyaml==6.0.1
requests==2.31.0
aiohttp==3.9.1
numpy==1.26.2
matplotlib==3.8.2

---
# requirements-integrations.txt
slack-bolt==1.18.0
discord.py==2.3.2
botbuilder-core==4.15.0
botbuilder-schema==4.15.0
python-telegram-bot==20.7
aiohttp==3.9.1
asyncio==3.4.3

---
# requirements-analytics.txt
pandas==2.1.4
numpy==1.26.2
matplotlib==3.8.2
seaborn==0.13.0
plotly==5.17.0
jupyter==1.0.0
psycopg2-binary==2.9.9
redis==5.0.1

---
# docker-compose.override.yml
# Development overrides
version: '3.8'

services:
  tps-api:
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    volumes:
      - .:/app
    command: uvicorn tps_api_server:app --host 0.0.0.0 --port 8000 --reload

  tps-web:
    environment:
      - NODE_ENV=development
    volumes:
      - .:/app
    command: npm run dev

  tps-integrations:
    volumes:
      - .:/app
    command: python tps_integration_connectors.py --dev

---
# Makefile
.PHONY: build up down logs shell test clean deploy

# Default environment
ENV ?= development

# Build all services
build:
	docker-compose build

# Start all services
up:
	docker-compose up -d

# Stop all services
down:
	docker-compose down

# View logs
logs:
	docker-compose logs -f

# Open shell in API container
shell:
	docker-compose exec tps-api bash

# Run tests
test:
	docker-compose exec tps-api python -m pytest tests/

# Clean up everything
clean:
	docker-compose down -v --remove-orphans
	docker system prune -f

# Deploy to production
deploy:
	docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Initialize database
init-db:
	docker-compose exec tps-postgres psql -U tps_user -d tps_db -f /docker-entrypoint-initdb.d/init-db.sql

# Backup database
backup-db:
	docker-compose exec tps-postgres pg_dump -U tps_user tps_db > backup_$(shell date +%Y%m%d_%H%M%S).sql

# Restore database
restore-db:
	docker-compose exec -T tps-postgres psql -U tps_user tps_db < $(BACKUP_FILE)

# View system status
status:
	docker-compose ps
	docker-compose top

# Update all services
update:
	docker-compose pull
	docker-compose up -d --remove-orphans

# Monitor resources
monitor:
	docker stats

# Generate SSL certificates (for production)
ssl-certs:
	mkdir -p docker/ssl
	openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
		-keyout docker/ssl/tps.key \
		-out docker/ssl/tps.crt \
		-subj "/C=US/ST=State/L=City/O=Organization/CN=tps.example.com"
